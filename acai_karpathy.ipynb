{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "391c5b7c-45b4-4b79-859f-dc0eb185d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "from acai.autoencoders.base import AutoencoderBase\n",
    "from acai.backbones import build_simple_encoder, build_simple_decoder\n",
    "from acai.convolution_visualizer import ConvolutionVisualizer\n",
    "from acai.data import make_line_image, IMAGE_SIZE\n",
    "from acai.image_utils import collage_images, torch2numpy_image, draw_images\n",
    "from acai.wandb_logger import WandbLogger\n",
    "from acai.utils import init_weights_kaiming_normal, fix_seeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cb186e6-81f5-4f26-b98a-c035edc27896",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ab845",
   "metadata": {},
   "source": [
    "# Quick look into data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7018be30-164e-42fe-b945-abdf4a5f7d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 33104.21it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fix_seeds(0)\n",
    "angles = np.random.uniform(-3, 3, size=10)\n",
    "images = np.stack([make_line_image(angle) for angle in tqdm.tqdm(angles)])\n",
    "images = images / 255\n",
    "images = images.astype(np.float32)\n",
    "draw_images(images[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddba699-b143-4568-9ec7-8462a7f6c2d2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Common training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae88c517-6583-4c12-bb5c-53429e7222b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PI = 3.1416\n",
    "\n",
    "def generate_batch(batchsize: int) -> torch.Tensor:\n",
    "    angles = np.random.uniform(-PI, PI, size=batchsize)\n",
    "    images = [make_line_image(angle) for angle in angles]\n",
    "    batch = np.stack(images)\n",
    "    batch = batch / 255\n",
    "    batch = torch.FloatTensor(batch)\n",
    "    batch = batch.view(batchsize, 1, IMAGE_SIZE, IMAGE_SIZE)\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d933848-0f80-4c92-a0f9-ee55f48a9d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class Trainer:\n",
    "    N_EVAL_LOGGING_IMAGES = 3\n",
    "    EVAL_EVERY = 500\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        autoencoder: AutoencoderBase,\n",
    "        logger: Optional[WandbLogger] = None,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "        callbacks: list[callable] = [],\n",
    "    ):\n",
    "        self.autoencoder = autoencoder\n",
    "        self.logger = logger or WandbLogger('debug', 'acai_karpathy')\n",
    "        self.device = device\n",
    "        self.convolution_visualizer = ConvolutionVisualizer()\n",
    "        self.callbacks = callbacks\n",
    "        \n",
    "    def train(self, n_steps):\n",
    "        eval_batch = generate_batch(batchsize=64).to(self.device)\n",
    "        self.autoencoder = self.autoencoder.to(self.device)\n",
    "        for step in range(n_steps):\n",
    "            self._run_callbacks()\n",
    "            self._train_step()\n",
    "            if step % self.EVAL_EVERY == 0:\n",
    "                self._eval_step(eval_batch)\n",
    "            self.logger.commit()\n",
    "    \n",
    "    def _run_callbacks(self):\n",
    "        for callback in self.callbacks:\n",
    "            callback(self)\n",
    "\n",
    "    def _train_step(self) -> None:\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def _eval_step(self, batch):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4362e47-9ef7-44b7-886c-0e654a4fd21b",
   "metadata": {},
   "source": [
    "## Train AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3ffaba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderTrainer(Trainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        autoencoder: AutoencoderBase,\n",
    "        logger: Optional[WandbLogger] = None,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "    ):\n",
    "        super().__init__(autoencoder, logger, device)\n",
    "        self.optimizer = torch.optim.Adam(autoencoder.parameters(), lr=3e-4)\n",
    "        self.compute_loss = torch.nn.MSELoss()\n",
    "\n",
    "    def _train_step(self):\n",
    "        self.autoencoder.train()\n",
    "        batch = generate_batch(BATCHSIZE).to(self.device)\n",
    "        first_image = torch2numpy_image(batch[0])\n",
    "        out = self.autoencoder(batch)\n",
    "        loss = out['loss']\n",
    "        reconstructed_first_image = torch2numpy_image(out['reconstructed_images'][0])\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        self.logger.log_images(\n",
    "            \"images/ae/train/first_image_in_batch\", \n",
    "            collage_images([first_image, reconstructed_first_image])\n",
    "        )\n",
    "        self.logger.log({\"ae/train/loss\": loss.detach().item()})\n",
    "\n",
    "    def _eval_step(self, batch):\n",
    "        self.autoencoder.eval()\n",
    "        first_images = torch2numpy_image(batch[:self.N_EVAL_LOGGING_IMAGES])\n",
    "        out = self.autoencoder(batch)\n",
    "        loss = out['loss']\n",
    "\n",
    "        self.logger.log({\"ae/test/loss\": loss.detach().item()})\n",
    "        self.logger.log_images(\n",
    "            \"images/ae/eval/reconstruction\", \n",
    "            collage_images([first_images, torch2numpy_image(out['reconstructed_images'][:self.N_EVAL_LOGGING_IMAGES])])\n",
    "        )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dad25d2b-38be-412c-bd1b-83ab65fac187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from acai.autoencoders import AutoencoderDefault\n",
    "# fix_seeds(42)\n",
    "\n",
    "# logger = WandbLogger(run='debug', project='acai_karpathy', log_images_every=100)\n",
    "# encoder = build_simple_encoder(width_coef=1)\n",
    "# decoder = build_simple_decoder(width_coef=1)\n",
    "# autoencoder = AutoencoderDefault(encoder, decoder)\n",
    "# autoencoder.apply(init_weights_kaiming_normal)\n",
    "\n",
    "# trainer = AutoencoderTrainer(autoencoder, logger=logger, device=torch.device(\"cuda\"))\n",
    "# trainer.train(n_steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855394b5-a7ff-4ba6-a02a-5276f4e4813b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train ACAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f0822dc7-8dd6-4171-bbdd-610f6e539d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from acai.autoencoders.acai import ACAI\n",
    "\n",
    "\n",
    "class ACAITrainer(Trainer):\n",
    "    autoencoder: ACAI\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        autoencoder: ACAI,\n",
    "        logger: Optional[WandbLogger] = None,\n",
    "        device: torch.device = torch.device(\"cpu\"),\n",
    "        callbacks = [],\n",
    "    ):\n",
    "        super().__init__(autoencoder, logger, device, callbacks)\n",
    "        self.optimizer_ae = torch.optim.Adam([*autoencoder.encoder.parameters(), *autoencoder.decoder.parameters()], lr=3e-4)\n",
    "        self.optimizer_critic = torch.optim.Adam(autoencoder.critic.parameters(), lr=3e-4)\n",
    "        self._step_counter = 0\n",
    "    \n",
    "    def _train_step(self):\n",
    "        self._train_ae()\n",
    "        self._train_critic()\n",
    "        self._step_counter += 1\n",
    "    \n",
    "    def _train_ae(self):\n",
    "        self.autoencoder.train()\n",
    "        self.autoencoder.critic.eval()\n",
    "        batch1 = generate_batch(BATCHSIZE).to(self.device)\n",
    "        batch2 = generate_batch(BATCHSIZE).to(self.device)\n",
    "        first_image = torch2numpy_image(batch1[0])\n",
    "        out = self.autoencoder(batch1, batch2)\n",
    "        loss = out['loss']\n",
    "        self.optimizer_ae.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer_ae.step()\n",
    "\n",
    "        self.logger.log({\"ae/train/loss\": loss.detach().item()})\n",
    "        self.logger.log({\"ae/train/reconstruction_loss\": out['reconstruction_loss'].detach().item()})\n",
    "        self.logger.log({\"ae/train/interpolation_loss\": out['interpolation_loss'].detach().item()})\n",
    "        self.logger.log_images(\n",
    "            \"images/ae/train/first_image_in_batch\", \n",
    "            collage_images([first_image, torch2numpy_image(out['reconstructed_images'][0])])\n",
    "        )\n",
    "        self.logger.log_images(\n",
    "            \"images/ae/train/decoded_interpolation\",\n",
    "            torch2numpy_image(out[\"reconstructed_interpolated_images\"][0]),\n",
    "        )\n",
    "        \n",
    "    def _train_critic(self):\n",
    "        self.autoencoder.eval()\n",
    "        self.autoencoder.critic.train()\n",
    "        batch1 = generate_batch(BATCHSIZE).to(self.device)\n",
    "        batch2 = generate_batch(BATCHSIZE).to(self.device)\n",
    "        first_image = torch2numpy_image(batch1[0])\n",
    "        out = self.autoencoder.forward_critic(batch1, batch2)\n",
    "        loss = out['loss']\n",
    "        self.optimizer_critic.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer_critic.step()\n",
    "\n",
    "        self.logger.log({\"critic/train/loss\": loss.detach().item()})\n",
    "        self.logger.log({\"critic/train/alpha_recovery_loss\": out['alpha_recovery_loss'].detach().item()})\n",
    "        self.logger.log({\"critic/train/regularization_loss\": out['regularization_loss'].detach().item()})\n",
    "        self.logger.log_images(\n",
    "            \"images/critic/train/first_image_in_batch\", \n",
    "            collage_images([first_image, torch2numpy_image(out['reconstructed_images'][0])])\n",
    "        )\n",
    "        self.logger.log_images(\n",
    "            \"images/critic/train/decoded_interpolation\",\n",
    "            torch2numpy_image(out[\"reconstructed_interpolated_images\"][0]),\n",
    "        )\n",
    "        self.logger.log_images(\n",
    "            \"images/critic/train/blended_image\",\n",
    "            torch2numpy_image(out[\"blended_non_interpolated_images\"][0]),\n",
    "        )\n",
    "\n",
    "    def _eval_step(self, batch):\n",
    "        self.autoencoder.eval()\n",
    "        batch2 = generate_batch(BATCHSIZE).to(self.device)\n",
    "        first_images = torch2numpy_image(batch[:self.N_EVAL_LOGGING_IMAGES])\n",
    "        out = self.autoencoder(batch, batch2)\n",
    "        loss = out['loss']\n",
    "        reconstructed_first_images = torch2numpy_image(out['reconstructed_images'][:self.N_EVAL_LOGGING_IMAGES])\n",
    "        self.logger.log_images(\n",
    "            \"images/ae/eval/reconstruction\", \n",
    "            collage_images([first_images, reconstructed_first_images])\n",
    "        )\n",
    "        self.logger.log({\"ae/test/loss\": loss.detach().item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f630b888-9a1f-44f4-8ed5-83fc1ef030e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:icpytfph) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">debug</strong> at: <a href='https://wandb.ai/implausible_deniability/acai_karpathy/runs/icpytfph' target=\"_blank\">https://wandb.ai/implausible_deniability/acai_karpathy/runs/icpytfph</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231025_123222-icpytfph/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:icpytfph). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/maxim/acai/wandb/run-20231025_123258-vgvapie6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/implausible_deniability/acai_karpathy/runs/vgvapie6' target=\"_blank\">debug</a></strong> to <a href='https://wandb.ai/implausible_deniability/acai_karpathy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/implausible_deniability/acai_karpathy' target=\"_blank\">https://wandb.ai/implausible_deniability/acai_karpathy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/implausible_deniability/acai_karpathy/runs/vgvapie6' target=\"_blank\">https://wandb.ai/implausible_deniability/acai_karpathy/runs/vgvapie6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/maxim/acai/acai_karpathy.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m autoencoder\u001b[39m.\u001b[39mapply(init_weights_kaiming_normal)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m trainer \u001b[39m=\u001b[39m ACAITrainer(autoencoder, logger\u001b[39m=\u001b[39mlogger, device\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m), callbacks\u001b[39m=\u001b[39m[InterpolationCallback()])\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain(n_steps\u001b[39m=\u001b[39;49m\u001b[39m260000\u001b[39;49m)\n",
      "\u001b[1;32m/home/maxim/acai/acai_karpathy.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m \u001b[39mfor\u001b[39;00m step \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(n_steps):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_callbacks()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=24'>25</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_step()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m     \u001b[39mif\u001b[39;00m step \u001b[39m%\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mEVAL_EVERY \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_step(eval_batch)\n",
      "\u001b[1;32m/home/maxim/acai/acai_karpathy.ipynb Cell 14\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train_step\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_ae()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_critic()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step_counter \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32m/home/maxim/acai/acai_karpathy.ipynb Cell 14\u001b[0m line \u001b[0;36m5\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=55'>56</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_critic\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=56'>57</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer_critic\u001b[39m.\u001b[39;49mstep()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=59'>60</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mcritic/train/loss\u001b[39m\u001b[39m\"\u001b[39m: loss\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mitem()})\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X15sdnNjb2RlLXJlbW90ZQ%3D%3D?line=60'>61</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mlog({\u001b[39m\"\u001b[39m\u001b[39mcritic/train/alpha_recovery_loss\u001b[39m\u001b[39m\"\u001b[39m: out[\u001b[39m'\u001b[39m\u001b[39malpha_recovery_loss\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mitem()})\n",
      "File \u001b[0;32m~/miniconda3/envs/cafa-protein/lib/python3.10/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m}\u001b[39;00m\u001b[39m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbut got \u001b[39m\u001b[39m{\u001b[39;00mresult\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    281\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[39m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/cafa-protein/lib/python3.10/site-packages/torch/optim/optimizer.py:33\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     32\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefaults[\u001b[39m'\u001b[39m\u001b[39mdifferentiable\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m---> 33\u001b[0m     ret \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     34\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     35\u001b[0m     torch\u001b[39m.\u001b[39mset_grad_enabled(prev_grad)\n",
      "File \u001b[0;32m~/miniconda3/envs/cafa-protein/lib/python3.10/site-packages/torch/optim/adam.py:141\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    130\u001b[0m     beta1, beta2 \u001b[39m=\u001b[39m group[\u001b[39m'\u001b[39m\u001b[39mbetas\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m    132\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_init_group(\n\u001b[1;32m    133\u001b[0m         group,\n\u001b[1;32m    134\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    139\u001b[0m         state_steps)\n\u001b[0;32m--> 141\u001b[0m     adam(\n\u001b[1;32m    142\u001b[0m         params_with_grad,\n\u001b[1;32m    143\u001b[0m         grads,\n\u001b[1;32m    144\u001b[0m         exp_avgs,\n\u001b[1;32m    145\u001b[0m         exp_avg_sqs,\n\u001b[1;32m    146\u001b[0m         max_exp_avg_sqs,\n\u001b[1;32m    147\u001b[0m         state_steps,\n\u001b[1;32m    148\u001b[0m         amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    149\u001b[0m         beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    150\u001b[0m         beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    151\u001b[0m         lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    152\u001b[0m         weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    153\u001b[0m         eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    154\u001b[0m         maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    155\u001b[0m         foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    156\u001b[0m         capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    157\u001b[0m         differentiable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mdifferentiable\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    158\u001b[0m         fused\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mfused\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[1;32m    159\u001b[0m         grad_scale\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mgrad_scale\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    160\u001b[0m         found_inf\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mfound_inf\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/miniconda3/envs/cafa-protein/lib/python3.10/site-packages/torch/optim/adam.py:281\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    279\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 281\u001b[0m func(params,\n\u001b[1;32m    282\u001b[0m      grads,\n\u001b[1;32m    283\u001b[0m      exp_avgs,\n\u001b[1;32m    284\u001b[0m      exp_avg_sqs,\n\u001b[1;32m    285\u001b[0m      max_exp_avg_sqs,\n\u001b[1;32m    286\u001b[0m      state_steps,\n\u001b[1;32m    287\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[1;32m    288\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[1;32m    289\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[1;32m    290\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    291\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    292\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    293\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[1;32m    294\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable,\n\u001b[1;32m    295\u001b[0m      differentiable\u001b[39m=\u001b[39;49mdifferentiable,\n\u001b[1;32m    296\u001b[0m      grad_scale\u001b[39m=\u001b[39;49mgrad_scale,\n\u001b[1;32m    297\u001b[0m      found_inf\u001b[39m=\u001b[39;49mfound_inf)\n",
      "File \u001b[0;32m~/miniconda3/envs/cafa-protein/lib/python3.10/site-packages/torch/optim/adam.py:509\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    506\u001b[0m     torch\u001b[39m.\u001b[39m_foreach_div_(exp_avg_sq_sqrt, bias_correction2_sqrt)\n\u001b[1;32m    507\u001b[0m     denom \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_foreach_add(exp_avg_sq_sqrt, eps)\n\u001b[0;32m--> 509\u001b[0m torch\u001b[39m.\u001b[39;49m_foreach_addcdiv_(params_, device_exp_avgs, denom, step_size)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fix_seeds(42)\n",
    "\n",
    "logger = WandbLogger(run='debug', project='acai_karpathy', log_images_every=100)\n",
    "encoder = build_simple_encoder(width_coef=1)\n",
    "decoder = build_simple_decoder(width_coef=1)\n",
    "critic = build_simple_encoder(width_coef=1)\n",
    "autoencoder = ACAI(encoder, decoder, critic)\n",
    "autoencoder.apply(init_weights_kaiming_normal)\n",
    "\n",
    "trainer = ACAITrainer(autoencoder, logger=logger, device=torch.device(\"cuda\"), callbacks=[InterpolationCallback()])\n",
    "trainer.train(n_steps=260000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cafa-protein",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
