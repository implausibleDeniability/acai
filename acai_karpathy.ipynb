{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "391c5b7c-45b4-4b79-859f-dc0eb185d11b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import tqdm\n",
    "import wandb\n",
    "\n",
    "from acai.autoencoders.base import AutoencoderBase\n",
    "from acai.backbones import build_simple_encoder, build_simple_decoder\n",
    "from acai.data.line_dataloader import LineDataLoader\n",
    "# from acai.image_utils import collage_images, torch2numpy_image, draw_images\n",
    "from acai.wandb_logger import WandbLogger\n",
    "from acai.utils import init_weights_kaiming_normal, fix_seeds\n",
    "# from acai.monitoring.base import MonitoringCallbackBase\n",
    "# from acai.monitoring.factory import MonitoringFactory, MonitoringType\n",
    "from acai.training.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cb186e6-81f5-4f26-b98a-c035edc27896",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a05ab845",
   "metadata": {},
   "source": [
    "# Quick look into data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7018be30-164e-42fe-b945-abdf4a5f7d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 25970.92it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from acai.data.line_image_generation import make_line_image\n",
    "from acai.image_utils import draw_images\n",
    "fix_seeds(0)\n",
    "angles = np.random.uniform(-3, 3, size=10)\n",
    "images = np.stack([make_line_image(angle) for angle in tqdm.tqdm(angles)])\n",
    "images = images / 255\n",
    "images = images.astype(np.float32)\n",
    "draw_images(images[:6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4362e47-9ef7-44b7-886c-0e654a4fd21b",
   "metadata": {},
   "source": [
    "## Train AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ffaba6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoencoderTrainer(Trainer):\n",
    "    def _configure_optimizers(self):\n",
    "        self.optimizer = torch.optim.Adam(self.autoencoder.parameters(), lr=3e-4)\n",
    "\n",
    "    def _train_step(self):\n",
    "        self.autoencoder.train()\n",
    "        batch = self.dataloader.get_train_batch()\n",
    "        first_image = torch2numpy_image(batch[0])\n",
    "        out = self.autoencoder(batch)\n",
    "        loss = out['loss']\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "\n",
    "        self.logger.log({\"ae/train/loss\": loss.detach().item()})\n",
    "        self.logger.log_images(\n",
    "            \"ae/train/images/first_image_in_batch_reconstruction\", \n",
    "            collage_images([\n",
    "                first_image, \n",
    "                torch2numpy_image(out['reconstructed_images'][0]),\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    def _eval_step(self, batch):\n",
    "        self.autoencoder.eval()\n",
    "        out = self.autoencoder(batch)\n",
    "        loss = out['loss']\n",
    "        self.logger.log({\"ae/test/loss\": loss.detach().item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dad25d2b-38be-412c-bd1b-83ab65fac187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:65v0ghcs) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ae_refactored_trainer</strong> at: <a href='https://wandb.ai/implausible_deniability/acai_karpathy/runs/65v0ghcs' target=\"_blank\">https://wandb.ai/implausible_deniability/acai_karpathy/runs/65v0ghcs</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231027_074128-65v0ghcs/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:65v0ghcs). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/maxim/acai/wandb/run-20231027_074142-6n877lok</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/implausible_deniability/acai_karpathy/runs/6n877lok' target=\"_blank\">ae_refactored_trainer</a></strong> to <a href='https://wandb.ai/implausible_deniability/acai_karpathy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/implausible_deniability/acai_karpathy' target=\"_blank\">https://wandb.ai/implausible_deniability/acai_karpathy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/implausible_deniability/acai_karpathy/runs/6n877lok' target=\"_blank\">https://wandb.ai/implausible_deniability/acai_karpathy/runs/6n877lok</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'batch_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/maxim/acai/acai_karpathy.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m autoencoder \u001b[39m=\u001b[39m AutoencoderDefault(encoder, decoder)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m autoencoder\u001b[39m.\u001b[39mapply(init_weights_kaiming_normal)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m trainer \u001b[39m=\u001b[39m AutoencoderTrainer(autoencoder, dataloader, logger\u001b[39m=\u001b[39;49mlogger, device\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mdevice(\u001b[39m\"\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bshamil/home/maxim/acai/acai_karpathy.ipynb#X13sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m trainer\u001b[39m.\u001b[39mtrain(n_steps\u001b[39m=\u001b[39m\u001b[39m260000\u001b[39m)\n",
      "File \u001b[0;32m~/acai/acai/training/trainer.py:26\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, autoencoder, dataloader, logger, device)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m device\n\u001b[1;32m     25\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_configure_optimizers()\n\u001b[0;32m---> 26\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_configure_monitorings()\n",
      "File \u001b[0;32m~/acai/acai/training/trainer.py:33\u001b[0m, in \u001b[0;36mTrainer._configure_monitorings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_configure_monitorings\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m     32\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmonitorings \u001b[39m=\u001b[39m [\n\u001b[0;32m---> 33\u001b[0m         MonitoringFactory()\u001b[39m.\u001b[39;49mbuild(MonitoringType\u001b[39m.\u001b[39;49mreconstruction, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataloader, n_images\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m),\n\u001b[1;32m     34\u001b[0m         MonitoringFactory()\u001b[39m.\u001b[39mbuild(MonitoringType\u001b[39m.\u001b[39minterpolation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader, n_images\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m),\n\u001b[1;32m     35\u001b[0m     ]\n",
      "File \u001b[0;32m~/acai/acai/monitoring/factory.py:19\u001b[0m, in \u001b[0;36mMonitoringFactory.build\u001b[0;34m(self, monitoring_type, dataloader, n_images)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[39mreturn\u001b[39;00m InterpolationMonitoring(images[:n_images], images[n_images:])\n\u001b[1;32m     18\u001b[0m \u001b[39melif\u001b[39;00m monitoring_type \u001b[39m==\u001b[39m MonitoringType\u001b[39m.\u001b[39mreconstruction:\n\u001b[0;32m---> 19\u001b[0m     images \u001b[39m=\u001b[39m dataloader\u001b[39m.\u001b[39;49mget_eval_batch(n_images \u001b[39m*\u001b[39;49m \u001b[39m2\u001b[39;49m)\n\u001b[1;32m     20\u001b[0m     \u001b[39mreturn\u001b[39;00m ReconstructionMonitoring(images)\n\u001b[1;32m     21\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/acai/acai/data/line_dataloader.py:18\u001b[0m, in \u001b[0;36mLineDataLoader.get_eval_batch\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_eval_batch\u001b[39m(\u001b[39mself\u001b[39m, batch_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 18\u001b[0m     batch_size \u001b[39m=\u001b[39m batch_size \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size\n\u001b[1;32m     19\u001b[0m     \u001b[39mreturn\u001b[39;00m generate_batch(batch_size)\u001b[39m.\u001b[39mto(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdevice)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'batch_size'"
     ]
    }
   ],
   "source": [
    "from acai.autoencoders.autoencoder import AutoencoderDefault\n",
    "fix_seeds(42)\n",
    "\n",
    "dataloader = LineDataLoader\n",
    "logger = WandbLogger(run='ae_refactored_trainer', project='acai_karpathy', log_images_every=100)\n",
    "encoder = build_simple_encoder(width_coef=1)\n",
    "decoder = build_simple_decoder(width_coef=1)\n",
    "autoencoder = AutoencoderDefault(encoder, decoder)\n",
    "autoencoder.apply(init_weights_kaiming_normal)\n",
    "\n",
    "trainer = AutoencoderTrainer(autoencoder, dataloader, logger=logger, device=torch.device(\"cuda\"))\n",
    "trainer.train(n_steps=260000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855394b5-a7ff-4ba6-a02a-5276f4e4813b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Train ACAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0822dc7-8dd6-4171-bbdd-610f6e539d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from acai.autoencoders.acai import ACAI\n",
    "from acai.monitoring.interpolation import InterpolationMonitoring\n",
    "\n",
    "\n",
    "class ACAITrainer(Trainer):\n",
    "    def _configure_optimizers(self):\n",
    "        self.optimizer_ae = torch.optim.Adam(\n",
    "            [\n",
    "                *self.autoencoder.encoder.parameters(), \n",
    "                *self.autoencoder.decoder.parameters(),\n",
    "            ], \n",
    "            lr=3e-4\n",
    "        )\n",
    "        self.optimizer_critic = torch.optim.Adam(self.autoencoder.critic.parameters(), lr=3e-4)\n",
    "    \n",
    "    def _train_step(self):\n",
    "        self._train_ae()\n",
    "        self._train_critic()\n",
    "    \n",
    "    def _train_ae(self):\n",
    "        batch = self.dataloader.get_train_batch()\n",
    "        batch4interpolation = self.dataloader.get_train_batch()\n",
    "        first_image = torch2numpy_image(batch[0])\n",
    "        out = self.autoencoder(batch, batch4interpolation)\n",
    "        self.optimizer_ae.zero_grad()\n",
    "        out['loss'].backward()\n",
    "        self.optimizer_ae.step()\n",
    "\n",
    "        self.logger.log({\"ae/train/loss\": out['loss'].detach().item()})\n",
    "        self.logger.log({\"ae/train/reconstruction_loss\": out['reconstruction_loss'].detach().item()})\n",
    "        self.logger.log({\"ae/train/interpolation_loss\": out['interpolation_loss'].detach().item()})\n",
    "        self.logger.log_images(\n",
    "            \"ae/train/images/first_image_in_batch_reconstruction\", \n",
    "            collage_images([first_image, torch2numpy_image(out['reconstructed_images'][0])])\n",
    "        )\n",
    "        self.logger.log_images(\n",
    "            \"ae/train/images/decoded_interpolation\",\n",
    "            torch2numpy_image(out[\"reconstructed_interpolated_images\"][0]),\n",
    "        )\n",
    "        \n",
    "    def _train_critic(self):\n",
    "        batch = self.dataloader.get_train_batch()\n",
    "        batch4interpolation = self.dataloader.get_train_batch()\n",
    "        first_image = torch2numpy_image(batch[0])\n",
    "        out = self.autoencoder.forward_critic(batch, batch4interpolation)\n",
    "        self.optimizer_critic.zero_grad()\n",
    "        out['loss'].backward()\n",
    "        self.optimizer_critic.step()\n",
    "\n",
    "        self.logger.log({\"critic/train/loss\": out['loss'].detach().item()})\n",
    "        self.logger.log({\"critic/train/alpha_recovery_loss\": out['alpha_recovery_loss'].detach().item()})\n",
    "        self.logger.log({\"critic/train/regularization_loss\": out['regularization_loss'].detach().item()})\n",
    "        self.logger.log_images(\n",
    "            \"critic/train/images/first_image_in_batch\", \n",
    "            collage_images([first_image, torch2numpy_image(out['reconstructed_images'][0])])\n",
    "        )\n",
    "        self.logger.log_images(\n",
    "            \"critic/train/images/decoded_interpolation\",\n",
    "            torch2numpy_image(out[\"reconstructed_interpolated_images\"][0]),\n",
    "        )\n",
    "        self.logger.log_images(\n",
    "            \"critic/train/images/blended_input_image\",\n",
    "            torch2numpy_image(out[\"blended_non_interpolated_images\"][0]),\n",
    "        )\n",
    "\n",
    "    def _eval_step(self, batch):\n",
    "        self.autoencoder.eval()\n",
    "        batch4interpolation = self.dataloader.get_train_batch()\n",
    "        out = self.autoencoder(batch, batch4interpolation)\n",
    "        self.logger.log({\"ae/test/loss\": out['loss'].detach().item()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f630b888-9a1f-44f4-8ed5-83fc1ef030e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:4pe7j297) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>ae/test/loss</td><td>█▆▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>ae/train/loss</td><td>█▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>ae/test/loss</td><td>0.00194</td></tr><tr><td>ae/train/loss</td><td>0.00219</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ae_final</strong> at: <a href='https://wandb.ai/implausible_deniability/acai_karpathy/runs/4pe7j297' target=\"_blank\">https://wandb.ai/implausible_deniability/acai_karpathy/runs/4pe7j297</a><br/>Synced 6 W&B file(s), 3640 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231027_063006-4pe7j297/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:4pe7j297). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.12 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/maxim/acai/wandb/run-20231027_065856-zc6ld8j8</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/implausible_deniability/acai_karpathy/runs/zc6ld8j8' target=\"_blank\">acai_final</a></strong> to <a href='https://wandb.ai/implausible_deniability/acai_karpathy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/implausible_deniability/acai_karpathy' target=\"_blank\">https://wandb.ai/implausible_deniability/acai_karpathy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/implausible_deniability/acai_karpathy/runs/zc6ld8j8' target=\"_blank\">https://wandb.ai/implausible_deniability/acai_karpathy/runs/zc6ld8j8</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fix_seeds(42)\n",
    "\n",
    "logger = WandbLogger(run='acai__refactored_trainer', project='acai_karpathy', log_images_every=100)\n",
    "encoder = build_simple_encoder(width_coef=1)\n",
    "decoder = build_simple_decoder(width_coef=1)\n",
    "critic = build_simple_encoder(width_coef=1)\n",
    "autoencoder = ACAI(encoder, decoder, critic)\n",
    "autoencoder.apply(init_weights_kaiming_normal)\n",
    "\n",
    "trainer = ACAITrainer(autoencoder, dataloader, logger=logger, device=torch.device(\"cuda\"))\n",
    "trainer.train(n_steps=260000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cafa-protein",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
